{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary Library \n",
    "import torchvision\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd566406",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad48ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    \n",
    "    training_dir = \"/home/kwanzo/Programming/Deep Learning/FB-ISC/Images/Augmented_Images/output\"\n",
    "    train_batch_size = 10\n",
    "    train_number_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24a878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc2173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory names list used later\n",
    "sets = [os.listdir()[i] for i in range(len(os.listdir())) if 'set' in os.listdir()[i]]\n",
    "\n",
    "#list of images\n",
    "images = []\n",
    "for root, dirnames, f in os.walk('/home/kwanzo/Programming/Deep Learning/FB-ISC/Images/Augmented_Images/output'):\n",
    "    images.append(f)\n",
    "\n",
    "#First two elements are irrelevant\n",
    "images = images[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8033e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_columns():\n",
    "    #Building the first column of the dataframe of image pairs\n",
    "    image_names = sorted(images[0])\n",
    "    lst1 = []\n",
    "    flag = 0\n",
    "    for i in range(len(image_names)):\n",
    "        \n",
    "        while flag < 3:\n",
    "            lst1.append('set1/' + image_names[i])\n",
    "            flag += 1\n",
    "            \n",
    "        while flag < 5:\n",
    "            lst1.append(random.choice(sets[1:]) + '/' + image_names[i])\n",
    "            flag += 1\n",
    "            \n",
    "        flag = 0\n",
    "\n",
    "    #2nd column\n",
    "    lst2 = []\n",
    "    flag = 0\n",
    "    for i in range(len(image_names)):\n",
    "        while flag < 3:\n",
    "            lst2.append(random.choice(sets) + '/' + image_names[i])\n",
    "            flag += 1\n",
    "            \n",
    "        while flag < 5:\n",
    "            lst2.append(random.choice(sets) + '/' + image_names[random.randint(0, 3499)])\n",
    "            flag += 1\n",
    "            \n",
    "        flag = 0\n",
    "    \n",
    "    \n",
    "    #Labels\n",
    "    labels = []\n",
    "    for i in range(len(lst1)):\n",
    "        if lst1[i][4:] == lst2[i][4:]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    \n",
    "    return lst1, lst2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb875e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inintializing the columns and labels\n",
    "column1, column2, labels = df_columns()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353572b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe of images\n",
    "df = pd.DataFrame({'Image1': column1,\n",
    "                  'Image2': column2,\n",
    "                  'Label': labels})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b05948",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset():\n",
    "    \n",
    "    def __init__(self,df=None,training_dir=None,transform=None):\n",
    "        # used to prepare the labels and images path\n",
    "        self.training_df=df\n",
    "        self.training_dir = training_dir    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        # getting the image path\n",
    "        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n",
    "        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n",
    "        \n",
    "        \n",
    "        # Loading the image\n",
    "        img0 = Image.open(image1_path)\n",
    "        img1 = Image.open(image2_path)\n",
    "        img0 = img0.convert(\"RGB\")\n",
    "        img1 = img1.convert(\"RGB\")\n",
    "        \n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([int(self.training_df.iat[index,2])], dtype=np.float32))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d962f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset = SiameseNetworkDataset(df,training_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the sample of images and to check whether its loading properly\n",
    "\n",
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=8,\n",
    "                        pin_memory = True)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "\n",
    "print(example_batch[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7a8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking different pretrained models and their layers\n",
    "\n",
    "# mod = torchvision.models.resnet18(pretrained = True)\n",
    "# feat_lst = nn.Sequential(*(list(mod.children())))\n",
    "# feat_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class model_pretrained(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(model_pretrained, self).__init__()\n",
    "#         self.original_model = torchvision.models.resnet18(pretrained=True)\n",
    "#         for self.param in self.original_model.parameters():\n",
    "#             self.param.requires_grad = False\n",
    "#         self.num_ftrs = self.original_model.fc.in_features\n",
    "#         self.original_model.fc = nn.Linear(self.num_ftrs, 2)\n",
    "# #         self.features = nn.Sequential(\n",
    "# #             # stop at conv4\n",
    "# #             *list(self.original_model.children())[:-7]\n",
    "# #         )\n",
    "        \n",
    "# #       Defining the fully connected layers\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(12288, 1024),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout2d(p=0.5),\n",
    "            \n",
    "#             nn.Linear(1024, 128),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             nn.Linear(128, 2)\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "#     def forward_once(self, x):\n",
    "#     # Forward pass \n",
    "#         output = self.features(x)\n",
    "#         output = output.view(output.size()[0], -1)\n",
    "#         output = self.fc1(output)\n",
    "#         return output\n",
    "\n",
    "#     def forward(self, inp1, inp2):\n",
    "#         inp1 = self.forward_once(inp1)\n",
    "#         inp2 = self.forward_once(inp2)\n",
    "#         return inp1, inp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pretrained():\n",
    "    model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "    for param in model_conv.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    num_ftrs = model_conv.fc.in_features\n",
    "    \n",
    "    # Output size = 2\n",
    "    model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    model_conv = model_conv.to(device)\n",
    "    \n",
    "    return model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function \n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset as pytorch tensors using dataloader\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=Config.train_batch_size,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Siamese Networkt\n",
    "net = model_pretrained()\n",
    "# Decalre Loss Function\n",
    "criterion = ContrastiveLoss()\n",
    "# Declare Optimizer\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=1e-3, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    counter = []\n",
    "    loss_history = [] \n",
    "    iteration_number= 0\n",
    "    \n",
    "    for epoch in range(0,Config.train_number_epochs):\n",
    "        for i, data in enumerate(train_dataloader,0):\n",
    "            img0, img1 , label = data\n",
    "            img0, img1 , label = Variable(img0.cuda()), Variable(img1.cuda()), Variable(label.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            output1,output2 = net(img0), net(img1)\n",
    "            loss_contrastive = criterion(output1,output2,label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()\n",
    "            if i % 500 == 0 :\n",
    "                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "                iteration_number += 500\n",
    "                counter.append(iteration_number)\n",
    "                loss_history.append(loss_contrastive.item())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73aea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# Train the model\n",
    "model = train()\n",
    "torch.save(model.state_dict(), training_dir + \"/model.pt\")\n",
    "print(\"Model Saved Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f16540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "\n",
    "model = model_pretrained().to(device)\n",
    "model.load_state_dict(torch.load(training_dir + \"/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = SiameseNetworkDataset(df,training_dir,\n",
    "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,num_workers=6,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39fcc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        margin = 2\n",
    "\n",
    "        for mainImg, testImg, label in test_dataloader:\n",
    "            pred = None\n",
    "            \n",
    "            mainImg = mainImg.to(device)\n",
    "            # determine which category an image belongs to\n",
    "        \n",
    "            testImg = testImg.to(device)\n",
    "            output1, output2 = model(mainImg, testImg)\n",
    "            \n",
    "            #Euclidean Distance\n",
    "            result = F.pairwise_distance(output1.cuda(), output2.cuda())\n",
    "            if result <= margin and label.item() == 1:\n",
    "                correct += 1\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                print(\"Accuracy = {}\".format(100*(correct/count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "pytorchgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
